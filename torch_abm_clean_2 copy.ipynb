{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.10.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "from math import *\n",
    "\n",
    "from torchvision.transforms.functional import rotate\n",
    "\n",
    "import pygame\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = 16\n",
    "NUM_STATES = 3\n",
    "NUM_PERCEPTIONS = 16\n",
    "NUM_ACTIONS = 2\n",
    "RADIUS = 16\n",
    "RES = 64\n",
    "\n",
    "def to_plt(img, detach=True): \n",
    "    return img.squeeze(0).permute(1, 2, 0).detach().cpu().numpy() if detach \\\n",
    "        else img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "\n",
    "class RadConv(nn.Module):\n",
    "    def __init__(self, NI, NO, radius):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(NI, NO, 2*radius+1, padding=radius, padding_mode='circular', bias=None)\n",
    "        \n",
    "        avg_weight = t.zeros_like(self.conv.weight.data)\n",
    "        \n",
    "        for theta in np.arange(0,2*pi,pi/64.0):\n",
    "            avg_weight += rotate(self.conv.weight.data.detach().clone(), 180*theta/pi)/128.0\n",
    "        # for theta in np.arange(0,2*t.pi,t.pi/256.0):\n",
    "        #     avg_weight += rotate(self.conv.weight.data.detach().clone(), 180*theta/t.pi)/np.sqrt(512.0)\n",
    "                    \n",
    "        self.conv.weight.data = np.pi*avg_weight\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "        \n",
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, NI, NO = 1, radius=3):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = RadConv(NI, NO, radius)\n",
    "        # self.conv = nn.Conv2d(NI, NO, 2*radius+1, padding=radius, padding_mode='circular', bias=None)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.thresh = nn.Threshold(0.5, 0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.glu = nn.GLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.sigmoid(x)\n",
    "        # x = self.thresh(x)\n",
    "        # x = t.clamp(x, 0, 1)\n",
    "        x = t.heaviside((x - 0.5*t.min(x)), t.cuda.FloatTensor([0]))\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [1, 0],\n",
       "         [0, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1]], device='cuda:0'),\n",
       " tensor([[2],\n",
       "         [1],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [2],\n",
       "         [1],\n",
       "         [2],\n",
       "         [1],\n",
       "         [1],\n",
       "         [2]], device='cuda:0'),\n",
       " tensor([[2, 2],\n",
       "         [1, 1],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [0, 2],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [1, 0],\n",
       "         [0, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 2]], device='cuda:0'),\n",
       " tensor([[ 1, 13],\n",
       "         [56, 54],\n",
       "         [62, 17],\n",
       "         [20,  7],\n",
       "         [ 0, 48],\n",
       "         [41, 38],\n",
       "         [23, 23],\n",
       "         [49, 13],\n",
       "         [29, 39],\n",
       "         [43, 34],\n",
       "         [63, 21],\n",
       "         [40, 50],\n",
       "         [31,  0],\n",
       "         [18, 21],\n",
       "         [40, 19],\n",
       "         [37, 54]], device='cuda:0'))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = t.randint(RES, (NUM_AGENTS, 2)).cuda()\n",
    "directions = t.randint(2, (NUM_AGENTS, 2)).cuda()\n",
    "speeds = t.randint(1, 1+RES//32, (NUM_AGENTS, 1)).cuda()\n",
    "states = t.randint(255, (NUM_AGENTS, 3)).cuda()\n",
    "perceptions = t.rand((NUM_AGENTS, NUM_PERCEPTIONS)).cuda()\n",
    "# positions, directions, speeds, states, perceptions\n",
    "directions, speeds, directions*speeds, positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions = t.randint(RES, (1, 2)).cuda()\n",
    "# positions[0], positions[0, :], positions[0, 0], positions[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world = t.zeros((1, 3, RES, RES), dtype=t.long).cuda()\n",
    "# world[0, :, 10, 10] = states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world[0, :, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([109, 190, 140])\n",
      "1 13 tensor([109, 190, 140])\n",
      "tensor([ 91,  24, 147])\n",
      "56 54 tensor([ 91,  24, 147])\n",
      "tensor([147, 217, 124])\n",
      "62 17 tensor([147, 217, 124])\n",
      "tensor([ 43, 232, 101])\n",
      "20 7 tensor([ 43, 232, 101])\n",
      "tensor([ 44, 171,  42])\n",
      "0 48 tensor([ 44, 171,  42])\n",
      "tensor([162,  73,  80])\n",
      "41 38 tensor([162,  73,  80])\n",
      "tensor([ 69,  82, 100])\n",
      "23 23 tensor([ 69,  82, 100])\n",
      "tensor([  7, 127, 226])\n",
      "49 13 tensor([  7, 127, 226])\n",
      "tensor([46, 73, 46])\n",
      "29 39 tensor([46, 73, 46])\n",
      "tensor([134,  65,  10])\n",
      "43 34 tensor([134,  65,  10])\n",
      "tensor([ 42, 153, 127])\n",
      "63 21 tensor([ 42, 153, 127])\n",
      "tensor([173, 137, 181])\n",
      "40 50 tensor([173, 137, 181])\n",
      "tensor([133,  79, 168])\n",
      "31 0 tensor([133,  79, 168])\n",
      "tensor([246, 239, 112])\n",
      "18 21 tensor([246, 239, 112])\n",
      "tensor([229, 250,  73])\n",
      "40 19 tensor([229, 250,  73])\n",
      "tensor([156, 113,  96])\n",
      "37 54 tensor([156, 113,  96])\n"
     ]
    }
   ],
   "source": [
    "world = t.zeros((1, 3, RES, RES), dtype=t.long)\n",
    "for i in range(NUM_AGENTS):\n",
    "    state = states[i].cpu(); print(state)\n",
    "    x_i = positions[i, 0].cpu().numpy()\n",
    "    y_i = positions[i, 1].cpu().numpy()\n",
    "    print(x_i, y_i, state)\n",
    "    world[0, :, x_i, y_i] = state\n",
    "    # world[0, 1, positions[i, 0], positions[i, 1]] = directions[i, 0]\n",
    "    # world[0, 2, positions[i, 0], positions[i, 1]] = directions[i, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world[0, :, 50, 31]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb4264fa5c0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axs = plt.subplots(1,figsize=(8,8))\n",
    "axs.imshow(to_plt(world))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4470, 0.5432, 0.4329]], device='cuda:0'), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plt(world).shape\n",
    "\n",
    "avg_pool = F.adaptive_avg_pool2d(world.type(t.cuda.FloatTensor), (1, 1)).squeeze(3).squeeze(2)\n",
    "avg_pool, avg_pool.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "class Agent(nn.Module):\n",
    "    \n",
    "    def __init__(self, env, position = t.cuda.LongTensor(np.random.randint(RES, size=2)), action = t.cuda.FloatTensor(np.random.randint(1, RES//32, size=2)), state = t.rand(1, NUM_STATES).cuda(), perception = t.rand(1, NUM_PERCEPTIONS).cuda()):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.position = position; print(self.position.shape); print(position); \n",
    "        self.action = action; print(self.action.shape)\n",
    "        self.state = state; print(self.state.shape)\n",
    "        self.perception = perception; print(self.perception.shape)\n",
    "        self.perceptive_field = None\n",
    "\n",
    "        # self.action = action.view(-1, 1); print(self.action.shape)\n",
    "        # self.state = state.view(-1, 1); print(self.state.shape)\n",
    "        # self.perception = perception.view(-1, 1); print(self.perception.shape)\n",
    "        self.config = t.cat([self.perception.view(-1, NUM_PERCEPTIONS), self.state.view(-1, NUM_STATES), self.action.view(-1, NUM_ACTIONS)], dim = 1).cuda(); #print(self.config.shape)\n",
    "        \n",
    "        self.env.world[0, :, self.position[0, 0], self.position[0, 1]] = self.config\n",
    "        self.env.states[0, :, self.position[0, 0], self.position[0, 1]] = self.state\n",
    "        \n",
    "        # self.config = t.cat([self.perception, self.state, self.action], dim = 1); print(self.config.shape)\n",
    "        self.P = RadConv(NI = NUM_PERCEPTIONS+NUM_STATES+NUM_ACTIONS, NO = NUM_PERCEPTIONS, radius = RADIUS).cuda(); #things in the environment; other agents states, their perception etc; NUM_AGENTS x NUM_STATES x NUM_PERCEPTIONS\n",
    "        self.max_pool = lambda x: F.adaptive_max_pool2d(x.type(t.cuda.FloatTensor), (1, 1)).cuda().squeeze(3).squeeze(2)\n",
    "        # self.conv = nn.Conv2d(NUM_AGENTS*NUM_PERCEPTIONS*NUM_STATES, NUM_PERCEPTIONS*NUM_STATES, 2*radius+1, padding=radius, padding_mode='circular', bias=None)\n",
    "        # self.S = nn.Linear(RES*RES*(NUM_PERCEPTIONS), NUM_STATES, bias=False).cuda()\n",
    "        # self.A = nn.Linear(RES*RES*(NUM_PERCEPTIONS), NUM_ACTIONS, bias=False).cuda()\n",
    "        self.S = nn.Linear(NUM_PERCEPTIONS, NUM_STATES, bias=False).cuda()\n",
    "        self.A = nn.Linear(NUM_PERCEPTIONS, NUM_ACTIONS, bias=False).cuda()\n",
    "\n",
    "        # self.fc3 = nn.Linear(NUM_PERCEPTIONS+NUM_STATES, NUM_STATES)\n",
    "        # self.fc4 = nn.Linear(NUM_PERCEPTIONS+NUM_STATES, NUM_ACTIONS)\n",
    "\n",
    "    def forward(self, world):\n",
    "        \n",
    "        perceptive_field = self.P(world); \n",
    "        self.perceptive_field = perceptive_field\n",
    "        self.perception = self.max_pool(perceptive_field); print(\"perception: \", self.perception, self.perception.shape)\n",
    "        self.state = self.S(self.perception); print(\"state: \", self.state); print(self.state.shape)\n",
    "        self.action = self.A(self.perception).type(t.cuda.LongTensor); print(self.action); print(self.action.shape)\n",
    "        \n",
    "        #update position\n",
    "        self.position = (self.position + self.action) % RES; print(self.position); print(self.position.shape)\n",
    "        #update config\n",
    "        self.config = t.tensor(t.cat([self.perception, self.state, self.action], dim=1)).cuda(); print(self.config); print(self.config.shape)\n",
    "\n",
    "        self.env.world[0, :, self.position[0, 0], self.position[0, 1]] = self.config\n",
    "        self.env.states[0, :, self.position[0, 0], self.position[0, 1]] = self.state\n",
    "        \n",
    "        return self.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(nn.Module):\n",
    "    def __init__(self, num_agents = NUM_AGENTS, num_states = NUM_STATES, num_perceptions = NUM_PERCEPTIONS, num_actions = NUM_ACTIONS, radius = RADIUS, size = RES):\n",
    "        super(Environment, self).__init__()\n",
    "        \n",
    "        self.num_agents = num_agents\n",
    "        # self.agents = [Agent(self) for i in range(num_agents)]\n",
    "        self.num_states = num_states\n",
    "        self.num_perceptions = num_perceptions\n",
    "        self.num_actions = num_actions\n",
    "        self.radius = radius\n",
    "        self.size = size\n",
    "\n",
    "        self.world = t.zeros((1, num_perceptions+num_states+num_actions, size, size), dtype=t.float).cuda() \n",
    "        self.states = t.zeros((1, num_states, size, size), dtype=t.float).cuda() \n",
    "\n",
    "        self.agents = []\n",
    "        self.add_agents()\n",
    "        \n",
    "    def add_agents(self, num_agents = None):\n",
    "        if num_agents is None:\n",
    "            num_agents = self.num_agents\n",
    "        for i in range(num_agents):    \n",
    "            position = t.randint(RES, (1, 2)).cuda()\n",
    "            direction = t.randint(2, (1, 2)).cuda()\n",
    "            speed = t.randint(1, 1+RES//32, (1, 1)).cuda()\n",
    "            state = t.randint(255, (1, 3)).cuda()\n",
    "            perception = t.rand((1, NUM_PERCEPTIONS)).cuda()\n",
    "            action = direction*speeds\n",
    "            self.agents.append(Agent(self, position = position, action = direction*speed, state = state, perception = perception))\n",
    "\n",
    "    @property\n",
    "    def positions(self):\n",
    "        return [a.position for a in self.agents]\n",
    "\n",
    "    def update(self, x = None):\n",
    "    \n",
    "        self.world = t.zeros((1, self.num_perceptions+self.num_states+self.num_actions, self.size, self.size), dtype=t.float).cuda() \n",
    "        self.states = t.zeros((1, self.num_states, self.size, self.size), dtype=t.float).cuda() \n",
    "        \n",
    "        for agent in self.agents:\n",
    "            agent.forward(self.world)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[53, 48]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[63, 37]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[20, 50]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[15, 17]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[60, 20]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[36, 29]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[38, 12]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[63,  0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[47,  9]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[20,  8]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[18, 21]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[63, 16]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[61, 37]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[12, 41]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[14, 62]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 2])\n",
      "tensor([[23,  2]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "E = Environment().cuda()\n",
    "# a = Agent(E).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[53, 48]], device='cuda:0'),\n",
       " tensor([[63, 37]], device='cuda:0'),\n",
       " tensor([[20, 50]], device='cuda:0'),\n",
       " tensor([[15, 17]], device='cuda:0'),\n",
       " tensor([[60, 20]], device='cuda:0'),\n",
       " tensor([[36, 29]], device='cuda:0'),\n",
       " tensor([[38, 12]], device='cuda:0'),\n",
       " tensor([[63,  0]], device='cuda:0'),\n",
       " tensor([[47,  9]], device='cuda:0'),\n",
       " tensor([[20,  8]], device='cuda:0'),\n",
       " tensor([[18, 21]], device='cuda:0'),\n",
       " tensor([[63, 16]], device='cuda:0'),\n",
       " tensor([[61, 37]], device='cuda:0'),\n",
       " tensor([[12, 41]], device='cuda:0'),\n",
       " tensor([[14, 62]], device='cuda:0'),\n",
       " tensor([[23,  2]], device='cuda:0')]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3c7d4b400>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axs = plt.subplots(1,figsize=(8,8))\n",
    "axs.imshow(to_plt(E.states).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[53, 48]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[63, 37]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[20, 50]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[15, 17]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[60, 20]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[36, 29]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[38, 12]], device='cuda:0')\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1506568/1700001880.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.config = t.tensor(t.cat([self.perception, self.state, self.action], dim=1)).cuda(); print(self.config); print(self.config.shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[63,  0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[47,  9]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[20,  8]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[18, 21]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[63, 16]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[61, 37]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[12, 41]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[14, 62]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n",
      "perception:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) torch.Size([1, 16])\n",
      "state:  tensor([[0., 0., 0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "torch.Size([1, 3])\n",
      "tensor([[0, 0]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[23,  2]], device='cuda:0')\n",
      "torch.Size([1, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 21])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3c7f7b5b0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "E.update()\n",
    "f, axs = plt.subplots(1,figsize=(8,8))\n",
    "axs.imshow(to_plt(E.states).astype(np.uint8))\n",
    "# with t.no_grad():\n",
    "#     E.update()\n",
    "#     f, axs = plt.subplots(1,figsize=(15,15))\n",
    "#     axs.imshow(to_plt(E.states))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
