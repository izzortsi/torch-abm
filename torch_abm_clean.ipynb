{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.10.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "from torchvision.transforms.functional import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIM = 3\n",
    "# CARRIERS = 9\n",
    "NUM_AGENTS = 10\n",
    "NUM_STATES = 3\n",
    "NUM_PERCEPTIONS = 3\n",
    "NUM_ACTIONS = 2\n",
    "RES = 512\n",
    "\n",
    "def rotate(x, angle): \n",
    "    ca = t.cos(angle)\n",
    "    sa = t.sin(angle)\n",
    "    \n",
    "    return t.cat([ca*x[:,:,:,0:1]+sa*x[:,:,:,1:2], -sa*x[:,:,:,0:1]+ca*x[:,:,:,1:2]], 3)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-0.25 * x))\n",
    "\n",
    "# dim 3 carries the x,y variation\n",
    "def mirror(p):\n",
    "    p = RES-1-p\n",
    "    w1 = t.le(p,0).long()\n",
    "    p = (1-w1)*p + w1*(-p)\n",
    "\n",
    "    p = RES-1-p\n",
    "    w1 = t.le(p,0).long()\n",
    "    p = (1-w1)*p + w1*(-p)\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "class RadConv(nn.Module):\n",
    "    def __init__(self, NI, NO, radius):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(NI, NO, 2*radius+1, padding=radius, padding_mode='circular', bias=None)\n",
    "        \n",
    "        avg_weight = t.zeros_like(self.conv.weight.data)\n",
    "        \n",
    "        for theta in np.arange(0,2*t.pi,t.pi/256.0):\n",
    "            avg_weight += rotate(self.conv.weight.data.detach().clone(), 180*theta/t.pi)/t.sqrt(512.0)\n",
    "        \n",
    "        #avg_weight /= avg_weight.sum(3).sum(2).unsqueeze(2).unsqueeze(3)\n",
    "        \n",
    "        self.conv.weight.data = avg_weight\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n",
      "torch.Size([512, 1])\n",
      "512\n",
      "torch.Size([512, 1])\n",
      "torch.Size([512, 2])\n"
     ]
    }
   ],
   "source": [
    "positions = t.rand(NUM_AGENTS, 2).cuda(); print(positions.shape)\n",
    "directions = t.tensor([theta for theta in np.arange(0,2*np.pi,np.pi/256.0)]).cuda().view(NUM_ACTIONS, 1); print(directions.shape)\n",
    "num_directions = directions.shape[0]; print(num_directions)\n",
    "speeds = t.tensor([speed for speed in t.rand(num_directions)]).cuda().view(NUM_ACTIONS, 1); print(speeds.shape)\n",
    "actions = t.cat([speeds, directions], 1); print(actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 5\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    \n",
    "    def __init__(self, position = t.rand(RES, RES), action = t.rand(size = (1, NUM_ACTIONS)), state = t.rand(1, NUM_STATES), perception = t.rand(1, NUM_PERCEPTIONS)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.position = position; print(self.position.shape)\n",
    "        print(position)\n",
    "        self.action = action; print(self.action.shape)\n",
    "        self.state = state; print(self.state.shape)\n",
    "        self.perception = perception; print(self.perception.shape)\n",
    "\n",
    "        # self.action = action.view(-1, 1); print(self.action.shape)\n",
    "        # self.state = state.view(-1, 1); print(self.state.shape)\n",
    "        # self.perception = perception.view(-1, 1); print(self.perception.shape)\n",
    "        self.config = t.cat([self.perception.view(-1, NUM_PERCEPTIONS), self.state.view(-1, NUM_STATES), self.action.view(-1, NUM_ACTIONS)], dim = 1); print(self.config.shape)\n",
    "        \n",
    "        self.percept = RadConv(NI = NUM_PERCEPTIONS+NUM_STATES, NO = NUM_PERCEPTIONS+NUM_STATES, radius = radius) #things in the environment; other agents states, their perception etc; NUM_AGENTS x NUM_STATES x NUM_PERCEPTIONS\n",
    "        # self.conv = nn.Conv2d(NUM_AGENTS*NUM_PERCEPTIONS*NUM_STATES, NUM_PERCEPTIONS*NUM_STATES, 2*radius+1, padding=radius, padding_mode='circular', bias=None)\n",
    "        self.fc1 = nn.Linear(NUM_PERCEPTIONS+NUM_STATES, NUM_PERCEPTIONS+NUM_STATES)\n",
    "        self.fc2 = nn.Linear(NUM_PERCEPTIONS+NUM_STATES, NUM_PERCEPTIONS)\n",
    "        self.fc3 = nn.Linear(NUM_PERCEPTIONS+NUM_STATES, NUM_STATES)\n",
    "        self.fc4 = nn.Linear(NUM_PERCEPTIONS+NUM_STATES, NUM_ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.state)\n",
    "        perception, states = F.relu(self.percept(x)) #should be NUM_AGENTS x NUM_STATES x NUM_PERCEPTIONS -> NUM_AGENTS x NUM_STATES x NUM_PERCEPTIONS\n",
    "        # perception, states = F.relu(self.conv(x))\n",
    "        print(perception)\n",
    "        print(states)\n",
    "        self.perception = F.relu(self.fc1(t.tensor(t.cat([perception, states], dim=0)).view(-1, NUM_PERCEPTIONS+NUM_STATES))); print(self.perception)\n",
    "        self.perception = F.softmax(self.fc2(self.perception))\n",
    "        self.state = F.softmax(self.fc3(self.perception).view(-1, NUM_STATES))\n",
    "        self.action = F.softmax(self.fc4(self.perception).view(-1, NUM_ACTIONS))\n",
    "        self.config = t.tensor(t.cat([self.perception, self.state, self.action], dim=1))\n",
    "        return self.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512])\n",
      "tensor([[0.6436, 0.1657, 0.0183,  ..., 0.0146, 0.7554, 0.4294],\n",
      "        [0.8607, 0.8119, 0.4676,  ..., 0.3828, 0.7251, 0.3021],\n",
      "        [0.7583, 0.6176, 0.8215,  ..., 0.7909, 0.0720, 0.1656],\n",
      "        ...,\n",
      "        [0.6884, 0.4218, 0.9399,  ..., 0.4075, 0.6524, 0.0902],\n",
      "        [0.1690, 0.3186, 0.8907,  ..., 0.1667, 0.2425, 0.9091],\n",
      "        [0.7027, 0.3399, 0.7627,  ..., 0.4011, 0.8463, 0.0295]])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 518])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cos(): argument 'input' (position 1) must be Tensor, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=0'>1</a>\u001b[0m Agent()\u001b[39m.\u001b[39mconfig\n",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb Cell 5\u001b[0m in \u001b[0;36mAgent.__init__\u001b[0;34m(self, position, action, state, perception)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=13'>14</a>\u001b[0m \u001b[39m# self.action = action.view(-1, 1); print(self.action.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=14'>15</a>\u001b[0m \u001b[39m# self.state = state.view(-1, 1); print(self.state.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=15'>16</a>\u001b[0m \u001b[39m# self.perception = perception.view(-1, 1); print(self.perception.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperception\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, NUM_PERCEPTIONS), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, NUM_STATES), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, NUM_ACTIONS)], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m); \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpercept \u001b[39m=\u001b[39m RadConv(NI \u001b[39m=\u001b[39;49m NUM_PERCEPTIONS\u001b[39m+\u001b[39;49mNUM_STATES, NO \u001b[39m=\u001b[39;49m NUM_PERCEPTIONS\u001b[39m+\u001b[39;49mNUM_STATES, radius \u001b[39m=\u001b[39;49m radius) \u001b[39m#things in the environment; other agents states, their perception etc; NUM_AGENTS x NUM_STATES x NUM_PERCEPTIONS\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=19'>20</a>\u001b[0m \u001b[39m# self.conv = nn.Conv2d(NUM_AGENTS*NUM_PERCEPTIONS*NUM_STATES, NUM_PERCEPTIONS*NUM_STATES, 2*radius+1, padding=radius, padding_mode='circular', bias=None)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=20'>21</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(NUM_PERCEPTIONS\u001b[39m+\u001b[39mNUM_STATES, NUM_PERCEPTIONS\u001b[39m+\u001b[39mNUM_STATES)\n",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb Cell 5\u001b[0m in \u001b[0;36mRadConv.__init__\u001b[0;34m(self, NI, NO, radius)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=37'>38</a>\u001b[0m avg_weight \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mzeros_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m theta \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mt\u001b[39m.\u001b[39mpi,t\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m256.0\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=40'>41</a>\u001b[0m     avg_weight \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rotate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mclone(), \u001b[39m180\u001b[39;49m\u001b[39m*\u001b[39;49mtheta\u001b[39m/\u001b[39;49mt\u001b[39m.\u001b[39;49mpi)\u001b[39m/\u001b[39mt\u001b[39m.\u001b[39msqrt(\u001b[39m512.0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=42'>43</a>\u001b[0m \u001b[39m#avg_weight /= avg_weight.sum(3).sum(2).unsqueeze(2).unsqueeze(3)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=44'>45</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m avg_weight\n",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb Cell 5\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(x, angle)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrotate\u001b[39m(x, angle): \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=11'>12</a>\u001b[0m     ca \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mcos(angle)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=12'>13</a>\u001b[0m     sa \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39msin(angle)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm_clean.ipynb#ch0000004?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mcat([ca\u001b[39m*\u001b[39mx[:,:,:,\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39msa\u001b[39m*\u001b[39mx[:,:,:,\u001b[39m1\u001b[39m:\u001b[39m2\u001b[39m], \u001b[39m-\u001b[39msa\u001b[39m*\u001b[39mx[:,:,:,\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mca\u001b[39m*\u001b[39mx[:,:,:,\u001b[39m1\u001b[39m:\u001b[39m2\u001b[39m]], \u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cos(): argument 'input' (position 1) must be Tensor, not numpy.float64"
     ]
    }
   ],
   "source": [
    "Agent().config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preys_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/torch_abm.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/torch_abm.ipynb#ch0000010?line=0'>1</a>\u001b[0m preys_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstate\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preys_' is not defined"
     ]
    }
   ],
   "source": [
    "preys_[0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Prey' object has no attribute 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000011?line=0'>1</a>\u001b[0m agents \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(preys\u001b[39m=\u001b[39mt\u001b[39m.\u001b[39mtensor([prey\u001b[39m.\u001b[39mstate \u001b[39mfor\u001b[39;00m prey \u001b[39min\u001b[39;00m preys_])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), predators\u001b[39m=\u001b[39mt\u001b[39m.\u001b[39mtensor([predator\u001b[39m.\u001b[39mstate \u001b[39mfor\u001b[39;00m predator \u001b[39min\u001b[39;00m predators])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb Cell 12\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000011?line=0'>1</a>\u001b[0m agents \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(preys\u001b[39m=\u001b[39mt\u001b[39m.\u001b[39mtensor([prey\u001b[39m.\u001b[39;49mstate \u001b[39mfor\u001b[39;00m prey \u001b[39min\u001b[39;00m preys_])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), predators\u001b[39m=\u001b[39mt\u001b[39m.\u001b[39mtensor([predator\u001b[39m.\u001b[39mstate \u001b[39mfor\u001b[39;00m predator \u001b[39min\u001b[39;00m predators])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Prey' object has no attribute 'state'"
     ]
    }
   ],
   "source": [
    "agents = dict(preys=t.tensor([prey.state for prey in preys_]).view(-1, 1), predators=t.tensor([predator.state for predator in predators]).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(nn.Module):\n",
    "    def __init__(self, spatial_contents, env_state, preys, predators):\n",
    "        super(Environment, self).__init__()\n",
    "        self.spatial_contents = spatial_contents\n",
    "        self.config = env_state\n",
    "        self.predators = predators\n",
    "        self.preys = preys\n",
    "        self.fc1 = nn.Linear((NUM_AGENTS*NUM_ACTIONS*NUM_PERCEPTIONS*NUM_STATES), NUM_AGENTS*NUM_ACTIONS) # env_variables + (positions + action + perceptions) of all agents -> some number\n",
    "        self.fc2 = nn.Linear((NUM_AGENTS*NUM_ACTIONS*NUM_PERCEPTIONS*NUM_STATES), NUM_AGENTS*NUM_PERCEPTIONS)\n",
    "        self.fc3 = nn.Linear((NUM_AGENTS*NUM_ACTIONS*NUM_PERCEPTIONS*NUM_STATES), NUM_AGENTS*NUM_STATES)\n",
    "        # self.fc3 = nn.Linear(128, contents)\n",
    "    \n",
    "    def _state(self):\n",
    "        self.config = t.cat(t.tensor([self.predators, self.preys]))\n",
    "        return self.config\n",
    "    \n",
    "    def __get__(self, x=None):\n",
    "        x = self._state()\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x = t.cat(\n",
    "        #     [t.tensor(list(self.env_state.values)).view(-1, 1), \n",
    "        #     t.flatten(t.tensor([[predator.state, predator.perceptions, predator.actions] for predator in self.predators])).view(-1, 1), \n",
    "        #     t.flatten(t.tensor([[prey.state, prey.perceptions, prey.actions] for prey in self.preys]))]).cuda()\n",
    "        \n",
    "        x = self.config.view(-1, 1)         \n",
    "        actions = F.softmax(F.relu(self.fc1(x)).view(NUM_AGENTS, NUM_ACTIONS))\n",
    "        perceptions = F.softmax(F.relu(self.fc2(x)).view(NUM_AGENTS, NUM_PERCEPTIONS))\n",
    "        states = F.softmax(F.relu(self.fc2(x)).view(NUM_AGENTS, NUM_STATES))\n",
    "        return t.cat([actions, perceptions, states]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of Predator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000016?line=0'>1</a>\u001b[0m env \u001b[39m=\u001b[39m Environment(t\u001b[39m.\u001b[39mtensor([]), t\u001b[39m.\u001b[39mcat(t\u001b[39m.\u001b[39;49mtensor([predators, preys]) ), preys, predators)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000016?line=2'>3</a>\u001b[0m Conf \u001b[39m=\u001b[39m env(env\u001b[39m.\u001b[39mconfig)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of Predator"
     ]
    }
   ],
   "source": [
    "env = Environment(t.tensor([]), t.cat(t.tensor([predators, preys]) ), preys, predators)\n",
    "\n",
    "Conf = env(env.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Agent.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000020?line=0'>1</a>\u001b[0m [p\u001b[39m.\u001b[39mforward() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39mpredators]\n",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb Cell 16\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000020?line=0'>1</a>\u001b[0m [p\u001b[39m.\u001b[39;49mforward() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39mpredators]\n",
      "\u001b[0;31mTypeError\u001b[0m: Agent.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "[p.forward() for p in env.predators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(nn.Module):\n",
    "    def __init__(self, spatial_contents, env_state, agents):\n",
    "        super(Environment, self).__init__()\n",
    "        self.spatial_contents = spatial_contents\n",
    "        self.state = env_state\n",
    "        self.predators = agents[\"predators\"]\n",
    "        self.preys = agents[\"preys\"]\n",
    "        self.fc1 = nn.Linear(len(env_state.values)*(NUM_AGENTS*NUM_ACTIONS*NUM_PERCEPTIONS*NUM_STATES), NUM_AGENTS*NUM_ACTIONS) # env_variables + (positions + action + perceptions) of all agents -> some number\n",
    "        self.fc2 = nn.Linear(len(env_state.values)*(NUM_AGENTS*NUM_ACTIONS*NUM_PERCEPTIONS*NUM_STATES), NUM_AGENTS*NUM_PERCEPTIONS)\n",
    "        self.fc3 = nn.Linear(len(env_state.values)*(NUM_AGENTS*NUM_ACTIONS*NUM_PERCEPTIONS*NUM_STATES), NUM_AGENTS*NUM_STATES)\n",
    "        # self.fc3 = nn.Linear(128, contents)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = t.cat(\n",
    "            [t.tensor(list(self.env_state.values)).view(-1, 1), \n",
    "            t.flatten(t.tensor([[predator.state, predator.perceptions, predator.actions] for predator in self.predators])).view(-1, 1), \n",
    "            t.flatten(t.tensor([[prey.state, prey.perceptions, prey.actions] for prey in self.preys]))]).cuda()\n",
    "            \n",
    "        actions = F.softmax(F.relu(self.fc1(x)).view(NUM_AGENTS, NUM_ACTIONS))\n",
    "        perceptions = F.softmax(F.relu(self.fc2(x)).view(NUM_AGENTS, NUM_ACTIONS))\n",
    "        states = F.softmax(F.relu(self.fc2(x)).view(NUM_AGENTS, NUM_ACTIONS))\n",
    "        return t.cat([actions, perceptions, states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predators' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/istrozzi/Documents/gm-ensemble/gm-ensemble_1.ipynb#ch0000012?line=0'>1</a>\u001b[0m t\u001b[39m.\u001b[39mflatten(t\u001b[39m.\u001b[39mtensor([[predator\u001b[39m.\u001b[39mstate, predator\u001b[39m.\u001b[39mperceptions, predator\u001b[39m.\u001b[39mactions] \u001b[39mfor\u001b[39;00m predator \u001b[39min\u001b[39;00m predators]))\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predators' is not defined"
     ]
    }
   ],
   "source": [
    "t.flatten(t.tensor([[predator.state, predator.perceptions, predator.actions] for predator in predators])).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "screen = pygame.display.set_mode((MULT*RES,MULT*RES), 0, 24)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
